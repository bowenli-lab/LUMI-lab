{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from modAL.models import ActiveLearner\n",
    "from skorch import NeuralNetClassifier\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build class for the skorch API\n",
    "class Torch_Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super(Torch_Model, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(12 * 12 * 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.convs(out)\n",
    "        out = out.view(-1, 12 * 12 * 64)\n",
    "        out = self.fcs(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the classifier\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "classifier = NeuralNetClassifier(\n",
    "    Torch_Model,\n",
    "    # max_epochs=100,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=None,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Data wrangling\n",
    "1. Reading data from torchvision\n",
    "2. Assembling initial training data for ActiveLearner\n",
    "3. Generating the pool\n",
    "\"\"\"\n",
    "\n",
    "mnist_data = MNIST(\".\", download=True, transform=ToTensor())\n",
    "dataloader = DataLoader(mnist_data, shuffle=True, batch_size=60000)\n",
    "X, y = next(iter(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "X_train, X_test, y_train, y_test = X[:50000], X[50000:], y[:50000], y[50000:]\n",
    "X_train = X_train.reshape(50000, 1, 28, 28)\n",
    "X_test = X_test.reshape(10000, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble initial data\n",
    "n_initial = 1000\n",
    "initial_idx = np.random.choice(range(len(X_train)), size=n_initial, replace=False)\n",
    "X_initial = X_train[initial_idx]\n",
    "y_initial = y_train[initial_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTraining the ActiveLearner\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the pool\n",
    "# remove the initial data from the training dataset\n",
    "X_pool = np.delete(X_train, initial_idx, axis=0)\n",
    "y_pool = np.delete(y_train, initial_idx, axis=0)\n",
    "\n",
    "\"\"\"\n",
    "Training the ActiveLearner\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.5579\u001b[0m  1.9494\n",
      "      2        \u001b[36m1.8733\u001b[0m  0.0489\n",
      "      3        \u001b[36m1.0252\u001b[0m  0.0440\n",
      "      4        \u001b[36m0.7877\u001b[0m  0.0467\n",
      "      5        \u001b[36m0.6321\u001b[0m  0.0491\n",
      "      6        \u001b[36m0.5159\u001b[0m  0.0487\n",
      "      7        \u001b[36m0.4544\u001b[0m  0.0473\n",
      "      8        \u001b[36m0.3942\u001b[0m  0.0462\n",
      "      9        0.4038  0.0418\n",
      "     10        \u001b[36m0.3502\u001b[0m  0.0422\n"
     ]
    }
   ],
   "source": [
    "# initialize ActiveLearner\n",
    "learner = ActiveLearner(\n",
    "    estimator=classifier,\n",
    "    X_training=X_initial,\n",
    "    y_training=y_initial,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.5581\u001b[0m  0.0528\n",
      "      2        \u001b[36m1.5429\u001b[0m  0.0559\n",
      "      3        \u001b[36m0.8327\u001b[0m  0.0507\n",
      "      4        \u001b[36m0.6260\u001b[0m  0.0562\n",
      "      5        \u001b[36m0.5081\u001b[0m  0.0492\n",
      "      6        \u001b[36m0.4362\u001b[0m  0.0542\n",
      "      7        \u001b[36m0.3577\u001b[0m  0.0499\n",
      "      8        \u001b[36m0.2902\u001b[0m  0.0726\n",
      "      9        \u001b[36m0.2707\u001b[0m  0.0553\n",
      "     10        \u001b[36m0.2688\u001b[0m  0.0579\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.7067\u001b[0m  0.0487\n",
      "      2        \u001b[36m1.7498\u001b[0m  0.0523\n",
      "      3        \u001b[36m1.2897\u001b[0m  0.0509\n",
      "      4        \u001b[36m0.8644\u001b[0m  0.0576\n",
      "      5        \u001b[36m0.6289\u001b[0m  0.0595\n",
      "      6        \u001b[36m0.5019\u001b[0m  0.0604\n",
      "      7        \u001b[36m0.3924\u001b[0m  0.0563\n",
      "      8        \u001b[36m0.3378\u001b[0m  0.0757\n",
      "      9        \u001b[36m0.2724\u001b[0m  0.0574\n",
      "     10        0.2897  0.0563\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.7083\u001b[0m  0.0641\n",
      "      2        \u001b[36m2.2995\u001b[0m  0.0754\n",
      "      3        2.2997  0.0648\n",
      "      4        \u001b[36m2.2976\u001b[0m  0.0686\n",
      "      5        2.2992  0.0666\n",
      "      6        \u001b[36m2.2970\u001b[0m  0.0692\n",
      "      7        2.2970  0.0616\n",
      "      8        2.2972  0.0572\n",
      "      9        \u001b[36m2.2967\u001b[0m  0.0572\n",
      "     10        2.2971  0.0565\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.6825\u001b[0m  0.0596\n",
      "      2        \u001b[36m1.8114\u001b[0m  0.0639\n",
      "      3        \u001b[36m1.1564\u001b[0m  0.0586\n",
      "      4        \u001b[36m0.8192\u001b[0m  0.0561\n",
      "      5        \u001b[36m0.5591\u001b[0m  0.0558\n",
      "      6        \u001b[36m0.5054\u001b[0m  0.0659\n",
      "      7        \u001b[36m0.4436\u001b[0m  0.0633\n",
      "      8        \u001b[36m0.3697\u001b[0m  0.0560\n",
      "      9        \u001b[36m0.3266\u001b[0m  0.0656\n",
      "     10        \u001b[36m0.3158\u001b[0m  0.0649\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.4801\u001b[0m  0.0705\n",
      "      2        \u001b[36m1.5669\u001b[0m  0.0771\n",
      "      3        \u001b[36m1.0876\u001b[0m  0.0633\n",
      "      4        \u001b[36m0.7440\u001b[0m  0.0590\n",
      "      5        \u001b[36m0.6560\u001b[0m  0.0687\n",
      "      6        \u001b[36m0.5010\u001b[0m  0.0671\n",
      "      7        \u001b[36m0.4302\u001b[0m  0.0683\n",
      "      8        \u001b[36m0.4257\u001b[0m  0.0791\n",
      "      9        \u001b[36m0.3901\u001b[0m  0.0745\n",
      "     10        \u001b[36m0.3810\u001b[0m  0.0682\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.5274\u001b[0m  0.0790\n",
      "      2        \u001b[36m2.2981\u001b[0m  0.0770\n",
      "      3        \u001b[36m2.2970\u001b[0m  0.0819\n",
      "      4        2.2989  0.0783\n",
      "      5        2.2981  0.0777\n",
      "      6        2.2978  0.0710\n",
      "      7        2.2974  0.0804\n",
      "      8        2.2973  0.0792\n",
      "      9        \u001b[36m2.2964\u001b[0m  0.0719\n",
      "     10        2.2984  0.0704\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3552\u001b[0m  0.0788\n",
      "      2        \u001b[36m1.1426\u001b[0m  0.0702\n",
      "      3        \u001b[36m0.9913\u001b[0m  0.0736\n",
      "      4        \u001b[36m0.8020\u001b[0m  0.0711\n",
      "      5        \u001b[36m0.6311\u001b[0m  0.0822\n",
      "      6        \u001b[36m0.6280\u001b[0m  0.0838\n",
      "      7        \u001b[36m0.4878\u001b[0m  0.0859\n",
      "      8        \u001b[36m0.3935\u001b[0m  0.0766\n",
      "      9        0.4016  0.0673\n",
      "     10        \u001b[36m0.3400\u001b[0m  0.0774\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2581\u001b[0m  0.0836\n",
      "      2        \u001b[36m1.4562\u001b[0m  0.0740\n",
      "      3        \u001b[36m1.1792\u001b[0m  0.0544\n",
      "      4        \u001b[36m1.0758\u001b[0m  0.0549\n",
      "      5        \u001b[36m0.8772\u001b[0m  0.0547\n",
      "      6        \u001b[36m0.7563\u001b[0m  0.0598\n",
      "      7        \u001b[36m0.6479\u001b[0m  0.0539\n",
      "      8        \u001b[36m0.5098\u001b[0m  0.0810\n",
      "      9        0.5220  0.0907\n",
      "     10        \u001b[36m0.4603\u001b[0m  0.0944\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.8298\u001b[0m  0.0854\n",
      "      2        \u001b[36m1.5920\u001b[0m  0.0881\n",
      "      3        \u001b[36m1.4023\u001b[0m  0.0892\n",
      "      4        \u001b[36m1.1576\u001b[0m  0.0995\n",
      "      5        \u001b[36m0.8369\u001b[0m  0.0896\n",
      "      6        \u001b[36m0.7310\u001b[0m  0.0872\n",
      "      7        \u001b[36m0.6576\u001b[0m  0.0856\n",
      "      8        \u001b[36m0.5997\u001b[0m  0.0872\n",
      "      9        \u001b[36m0.5334\u001b[0m  0.0842\n",
      "     10        \u001b[36m0.5029\u001b[0m  0.0815\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.4335\u001b[0m  0.0917\n",
      "      2        \u001b[36m1.6100\u001b[0m  0.0791\n",
      "      3        \u001b[36m1.3646\u001b[0m  0.0833\n",
      "      4        \u001b[36m1.1278\u001b[0m  0.0943\n",
      "      5        \u001b[36m1.0699\u001b[0m  0.0916\n",
      "      6        \u001b[36m0.9550\u001b[0m  0.0979\n",
      "      7        \u001b[36m0.7842\u001b[0m  0.0876\n",
      "      8        \u001b[36m0.6716\u001b[0m  0.0995\n",
      "      9        \u001b[36m0.6363\u001b[0m  0.0925\n",
      "     10        \u001b[36m0.6140\u001b[0m  0.0970\n"
     ]
    }
   ],
   "source": [
    "# the active learning loop\n",
    "n_queries = 10\n",
    "for idx in range(n_queries):\n",
    "    query_idx, query_instance = learner.query(X_pool, n_instances=100)\n",
    "    learner.teach(X_pool[query_idx], y_pool[query_idx], only_new=False)\n",
    "    # remove queried instance from pool\n",
    "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "    y_pool = np.delete(y_pool, query_idx, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9477\n"
     ]
    }
   ],
   "source": [
    "# the final accuracy score\n",
    "print(learner.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unimol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
